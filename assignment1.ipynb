{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMP5328 - Advanced Machine Learning\n",
    "## Assignment 1: Non-negative Matrix Factorization\n",
    "----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Semester 2, 2025)**\n",
    "\n",
    "In this ipython notebook, we provide some example code for assignment1.\n",
    "+ Load Data.\n",
    "    - ORL dataset. \n",
    "    - Extended YaleB dataset. \n",
    "    - AR dataset (**optional**).\n",
    "+ Perform Evaluation. \n",
    "   - Relative Reconstruction Errors.\n",
    "   - Accuracy, NMI (**optional**).\n",
    "\n",
    "Lecturer: Tongliang Liu.\n",
    "\n",
    "**Note: All datasets can be used only for this assignment and you are not allowed to distribute these datasets. If you want to use AR dataset, you need to apply it by yourself (we do not provide AR dataset due to the problem of license, please find more details in http://www2.ece.ohio-state.edu/~aleix/ARdatabase.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "\n",
    "### 1.0 Data Folder"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T03:25:51.755746Z",
     "start_time": "2025-09-22T03:25:41.379326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Tuple\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-09-22T02:38:57.049035Z",
     "start_time": "2025-09-22T02:38:56.941767Z"
    }
   },
   "source": [
    "# The structure of data folder.\n",
    "!ls -l data"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Tree structure of data folder.\n",
    "├── CroppedAR\n",
    "    ├── M-001-01.bmp\n",
    "    ├── M-001-01.txt\n",
    "    ├── M-001-02.bmp\n",
    "    ├── M-001-02.txt\n",
    "    ├── ...\n",
    "├── CroppedYaleB\n",
    "│   ├── yaleB01\n",
    "│   ├── yaleB02\n",
    "│   ...\n",
    "│   ├── yaleB38\n",
    "│   └── yaleB39\n",
    "└── ORL\n",
    "    ├── s1\n",
    "    ├── s2\n",
    "    ├── s3\n",
    "    ├── ...\n",
    "    ├── s40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load ORL Dataset and Extended YaleB Dataset.\n",
    "+ ORL dataset contains ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement). The size of each image is 92x112 pixels, with 256 grey levels per pixel. To further reduce the computation complexity, you can resize all images to 30x37 pixels.\n",
    "\n",
    "+ Extended YaleB dataset contains 2414 images of 38 human subjects under 9 poses and 64 illumination conditions. All images are manually aligned, cropped, and then resized to 168x192 pixels. To further reduce the computation complexity, you can resize all images to 42x48 pixels."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T12:00:17.046335Z",
     "start_time": "2025-09-21T12:00:15.658819Z"
    }
   },
   "source": [
    "def load_data(root='data/CroppedYaleB', reduce=4):\n",
    "    \"\"\" \n",
    "    Load ORL (or Extended YaleB) dataset to numpy array.\n",
    "    \n",
    "    Args:\n",
    "        root: path to dataset.\n",
    "        reduce: scale factor for zooming out images.\n",
    "        \n",
    "    \"\"\" \n",
    "    images, labels = [], []\n",
    "\n",
    "    for i, person in enumerate(sorted(os.listdir(root))):\n",
    "        \n",
    "        if not os.path.isdir(os.path.join(root, person)):\n",
    "            continue\n",
    "        \n",
    "        for fname in os.listdir(os.path.join(root, person)):    \n",
    "            \n",
    "            # Remove background images in Extended YaleB dataset.\n",
    "            if fname.endswith('Ambient.pgm'):\n",
    "                continue\n",
    "            \n",
    "            if not fname.endswith('.pgm'):\n",
    "                continue\n",
    "                \n",
    "            # load image.\n",
    "            img = Image.open(os.path.join(root, person, fname))\n",
    "            img = img.convert('L') # grey image.\n",
    "\n",
    "            # reduce computation complexity.\n",
    "            img = img.resize([s//reduce for s in img.size])\n",
    "\n",
    "            # TODO: preprocessing.\n",
    "\n",
    "            # convert image to numpy array.\n",
    "            img = np.asarray(img).reshape((-1,1))\n",
    "\n",
    "            # collect data and label.\n",
    "            images.append(img)\n",
    "            labels.append(i)\n",
    "\n",
    "    # concate all images and labels.\n",
    "    images = np.concatenate(images, axis=1)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-09-21T12:01:01.920203Z",
     "start_time": "2025-09-21T12:00:20.345191Z"
    }
   },
   "source": [
    "# Load ORL dataset.\n",
    "X, Y = load_data(root='data/ORL', reduce=2)\n",
    "print('ORL dataset: X.shape = {}, Y.shape = {}'.format(X.shape, Y.shape))\n",
    "\n",
    "# Load Extended YaleB dataset.\n",
    "X, Y = load_data(root='data/CroppedYaleB', reduce=4)\n",
    "print('Extended YalB dataset: X.shape = {}, Y.shape = {}'.format(X.shape, Y.shape))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORL dataset: X.shape = (2576, 400), Y.shape = (400,)\n",
      "Extended YalB dataset: X.shape = (2016, 2414), Y.shape = (2414,)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load AR Dataset (Optional) \n",
    "AR dataset contains 2600 images of 100 individuals (50 male and 50 female). All images have been cropped and resized to 120x165 pixels. To further reduce the computation complexity, you can resize all images to 40x55 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "def load_data_AR(root='data/CroppedAR', reduce=3):\n",
    "    \"\"\" \n",
    "    Load AR dataset to numpy array.\n",
    "    \n",
    "    Args:\n",
    "        root: path to AR dataset.\n",
    "        reduce: scale factor for zooming out images.\n",
    "        \n",
    "    \"\"\" \n",
    "    images, labels = [], []\n",
    "    \n",
    "    for fname in os.listdir(root):\n",
    "        \n",
    "        if not fname.endswith('.bmp'):\n",
    "            continue\n",
    "        \n",
    "        # get label.\n",
    "        label = int(fname[2:5])\n",
    "        if fname[0] == 'W': # start from 50\n",
    "            label += 50\n",
    "        \n",
    "        # load image.\n",
    "        img = Image.open(os.path.join(root, fname))\n",
    "        img = img.convert('L') # grey\n",
    "        \n",
    "        # reduce computation complexity.\n",
    "        img = img.resize([s//reduce for s in img.size])\n",
    "   \n",
    "        # TODO: preprocessing.\n",
    "        \n",
    "        # convert image to numpy array.\n",
    "        img = np.asarray(img).reshape((-1,1))\n",
    "        \n",
    "        # collect data and label.\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "        \n",
    "    # concate all images and labels.\n",
    "    images = np.concatenate(images, axis=1)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============ 2) Helpers ============\n",
    "\n",
    "def normalize_columns_01(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"按列缩放到[0,1]；如需自定义归一化策略，这里实现。\"\"\"\n",
    "    pass\n",
    "\n",
    "def guess_hw_from_d(d: int) -> tuple[int, int]:\n",
    "    \"\"\"根据向量维度 d 估计图像 (h, w)。若已知尺寸可直接跳过。\"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X, Y = load_data_AR(root='data/CroppedAR', reduce=3)\n",
    "# print('AR dataset: X.shape = {}, Y.shape = {}'.format(X.shape, Y.shape))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def salt_pepper(V: np.ndarray, p: float = 0.2, r: float = 0.5, seed: Optional[int] = None\n",
    "               ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    对列为样本的矩阵 V(d×n) 施加椒盐噪声。\n",
    "    p: 被替换像素比例（0~1）\n",
    "    r: 被替换为“盐”(最大值)的比例（其余为“椒”(最小值)）\n",
    "    返回: (V_noisy, noise_mask)，noise_mask=1 表示该像素被替换\n",
    "    \"\"\"\n",
    "    V = np.asarray(V, dtype=float)\n",
    "    d, n = V.shape\n",
    "    rng = np.random.default_rng(seed)\n",
    "    vmin = float(np.min(V))\n",
    "    vmax = float(np.max(V))\n",
    "\n",
    "    U = rng.random((d, n))\n",
    "    noise_idx = U < p\n",
    "    salt_mask = rng.random((d, n)) < r\n",
    "\n",
    "\n",
    "    V_noisy = V.copy()\n",
    "    V_noisy[noise_idx & salt_mask]  = vmax\n",
    "    V_noisy[noise_idx & ~salt_mask] = vmin\n",
    "    return V_noisy, noise_idx.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluation Metrics\n",
    "\n",
    "\n",
    "### 2.1 Relative Reconstruction Errors (RRE)\n",
    "\n",
    "To compare the robustness of different NMF algorithms, you can use the ```relative reconstruction errors```. Let $V$ denote the contaminated dataset (by adding noise), and $\\hat{V}$\n",
    " denote the clean dataset. Let $W$ and $H$ denote the factorization results on $V$, the ``relative reconstruction errors`` then can be defined as follows:\n",
    " \\begin{equation}\n",
    "    RRE = \\frac{ \\| \\hat{V} - WH \\|_F }{ \\| \\hat{V} \\|_F}.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Load ORL dataset ...\n",
      "V_hat.shape=(1110, 400), Y_hat.shape=(400,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Apply NMF ...\n",
      "W.shape=(1110, 40), H.shape=(40, 400)\n",
      "==> Evaluate RRE ...\n",
      "RRE = 0.22688415691467015\n"
     ]
    }
   ],
   "source": [
    "# Load dataset.\n",
    "print('==> Load ORL dataset ...')\n",
    "V_hat, Y_hat = load_data('data/ORL', reduce=3)\n",
    "print('V_hat.shape={}, Y_hat.shape={}'.format(V_hat.shape, Y_hat.shape))\n",
    "\n",
    "# Add Noise.\n",
    "V_noise = np.random.rand(*V_hat.shape) * 40\n",
    "V = V_hat + V_noise\n",
    "\n",
    "# Plot result.\n",
    "import matplotlib.pyplot as plt\n",
    "img_size = [i//3 for i in (92, 112)] # ORL\n",
    "ind = 2 # index of demo image.\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(V_hat[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image(Original)')\n",
    "plt.subplot(132)\n",
    "plt.imshow(V_noise[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Noise')\n",
    "plt.subplot(133)\n",
    "plt.imshow(V[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image(Noise)')\n",
    "plt.show()\n",
    "\n",
    "# TODO: you should implement NMF algorithms by yourself.\n",
    "print('==> Apply NMF ...')\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=len(set(Y_hat))) # set n_components to num_classes.\n",
    "W = model.fit_transform(V)\n",
    "H = model.components_\n",
    "print('W.shape={}, H.shape={}'.format(W.shape, H.shape))\n",
    "\n",
    "# Evaluate relative reconstruction errors.\n",
    "print('==> Evaluate RRE ...')\n",
    "RRE = np.linalg.norm(V_hat - W.dot(H)) / np.linalg.norm(V_hat)\n",
    "print('RRE = {}'.format(RRE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Evaluate Clustering Performance\n",
    "\n",
    "1. Accuracy.\n",
    "    \n",
    "    $$ Acc(Y, Y_{pred}) = \\frac{1}{n}\\sum\\limits_{i=1}^n 1\\{Y_{pred}(i) == Y(i)\\}$$\n",
    "        \n",
    "2. Normalized Mutual Information (NMI).\n",
    "\n",
    "    $$ NMI(Y, Y_{pred}) = \\frac{2 * I(Y, Y_{pred})}{H(Y) + H(Y_{pred})} $$\n",
    "    \n",
    "   where $ I(\\cdot,\\cdot) $ is mutual information and $ H(\\cdot) $ is entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Evaluate Acc and NMI ...\n",
      "Acc(NMI) = 0.5875 (0.7431)\n"
     ]
    }
   ],
   "source": [
    "def assign_cluster_label(X, Y):\n",
    "    kmeans = KMeans(n_clusters=len(set(Y))).fit(X)\n",
    "    Y_pred = np.zeros(Y.shape)\n",
    "    for i in set(kmeans.labels_):\n",
    "        ind = kmeans.labels_ == i\n",
    "        Y_pred[ind] = Counter(Y[ind]).most_common(1)[0][0] # assign label.\n",
    "    return Y_pred\n",
    "\n",
    "print('==> Evaluate Acc and NMI ...')\n",
    "\n",
    "# Assign cluster labels.\n",
    "Y_pred = assign_cluster_label(H.T, Y_hat)\n",
    "\n",
    "acc = accuracy_score(Y_hat, Y_pred)\n",
    "nmi = normalized_mutual_info_score(Y_hat, Y_pred)\n",
    "print('Acc(NMI) = {:.4f} ({:.4f})'.format(acc, nmi))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. NMF core algorithm\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.1 NMF L2 core algorithm\n",
    "Here is the process of L2 core algorithm"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def NMFL2(X: np.ndarray, k: int, max_iter: int = 300, tol: float = 1e-5, seed: int = 0) -> Tuple[np.ndarray, np.ndarray, List[float]]:\n",
    "    \"\"\"\n",
    "    L2-NMF（你的原始乘法更新）:\n",
    "      返回 (W, H, error_curve)\n",
    "    【内容保留与之前相同】\n",
    "    \"\"\"\n",
    "    V = np.mat(np.maximum(np.asarray(X, dtype=float), 0.0))  # ensure nonnegative, matrix type\n",
    "    m, n = V.shape\n",
    "    r = int(k)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    W = np.mat(rng.random((m, r)))\n",
    "    H = np.mat(rng.random((r, n)))\n",
    "    errs: List[float] = []\n",
    "    for _ in range(int(max_iter)):\n",
    "        E = V - W * H\n",
    "        err = float(np.sum(np.multiply(E, E)))\n",
    "        errs.append(err)\n",
    "        if err < tol:\n",
    "            break\n",
    "        a = W.T * V\n",
    "        b = W.T * W * H\n",
    "        for i in range(r):\n",
    "            for j in range(n):\n",
    "                if b[i, j] != 0:\n",
    "                    H[i, j] = H[i, j] * a[i, j] / b[i, j]\n",
    "        c = V * H.T\n",
    "        d = W * H * H.T\n",
    "        for i in range(m):\n",
    "            for j in range(r):\n",
    "                if d[i, j] != 0:\n",
    "                    W[i, j] = W[i, j] * c[i, j] / d[i, j]\n",
    "    return np.asarray(W), np.asarray(H), errs\n",
    "# https://www.cnblogs.com/zhibei/p/9373120.html"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.2 NMF L1 Algorithm\n",
    "Here is the realization of L1 Algorithm"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Some code\n",
    "def NMFL1_IRLS(X: np.ndarray, k: int, max_iter: int = 100, inner_iters: int = 3, eps: float = 1e-8, tol: float = 1e-4, seed: int = 0):\n",
    "    \"\"\"\n",
    "    L1-NMF（IRLS 框架）占位：\n",
    "      需要时把 IRLS 的加权乘法更新写进来，返回 (W, H, mae_curve)。\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4. Main\n",
    "Here is citation of above functions"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===== Config =====\n",
    "DATASET_ROOT = \"data/ORL\"           # 或 \"data/CroppedYaleB\"\n",
    "DATASET_TYPE = \"ORL\"                # \"ORL\" 或 \"YaleB\"（用于推 h,w）\n",
    "REDUCE       = 3 if DATASET_TYPE==\"ORL\" else 4\n",
    "USE_NOISE    = True                 # 是否加椒盐噪声\n",
    "P_NOISE      = 0.20                 # 被替换像素比例 p\n",
    "R_SALT       = 0.50                 # 盐(最大值)比例 r\n",
    "K            = None                 # 分解维度；None 则设为类别数\n",
    "MAX_ITER_L2  = 300\n",
    "TOL_L2       = 1e-5\n",
    "RUN_L1       = True                 # 是否跑 L1（若你已实现 NMFL1_IRLS）\n",
    "\n",
    "# ===== 1) Load dataset (列为样本 d×n) =====\n",
    "try:\n",
    "    X_clean, Y = load_data(root=DATASET_ROOT, reduce=REDUCE)\n",
    "except NameError:\n",
    "    # 如果你函数名是 load_data\n",
    "    X_clean, Y = load_data(root=DATASET_ROOT, reduce=REDUCE)\n",
    "print(\"X_clean:\", X_clean.shape, \"Y:\", Y.shape)\n",
    "\n",
    "# 推断图像尺寸（按数据集与 reduce）\n",
    "if DATASET_TYPE.upper() == \"ORL\":\n",
    "    # ORL 原始 112×92\n",
    "    h, w = 112//REDUCE, 92//REDUCE\n",
    "else:\n",
    "    # YaleB 原图规格不完全一致，这里用 d 的平方根近似；不对就自己改成固定 h,w\n",
    "    d = X_clean.shape[0]\n",
    "    hw = int(np.sqrt(d))\n",
    "    if hw*hw == d:\n",
    "        h = w = hw\n",
    "    else:\n",
    "        h = int(np.floor(np.sqrt(d)))\n",
    "        w = int(np.ceil(d / h))\n",
    "\n",
    "# ===== 2) （可选）加椒盐噪声 =====\n",
    "if USE_NOISE:\n",
    "    X, M = salt_pepper(X_clean, p=P_NOISE, r=R_SALT, seed=0)\n",
    "    # 可视化一张：原图 / 噪声mask / 加噪\n",
    "    try:\n",
    "        viz_triplet(X_clean, X, M, h, w, idx=2, suptitle=f\"Salt-Pepper p={P_NOISE}, r={R_SALT}\")\n",
    "    except Exception as e:\n",
    "        print(\"viz_triplet skipped:\", e)\n",
    "else:\n",
    "    X = X_clean\n",
    "\n",
    "# ===== 3) Run NMFs =====\n",
    "if K is None:\n",
    "    K = len(np.unique(Y)) if Y.size else 40\n",
    "\n",
    "# L2（你的手写实现）\n",
    "W2, H2, err2 = NMFL2(X, k=K, max_iter=MAX_ITER_L2, tol=TOL_L2, seed=0)\n",
    "print(f\"[L2] W:{W2.shape} H:{H2.shape} iters:{len(err2)}  RRE(clean):\",\n",
    "      np.linalg.norm(X_clean - W2 @ H2) / (np.linalg.norm(X_clean) + 1e-12))\n",
    "\n",
    "# （可选）L1（如果你已实现 NMFL1_IRLS）\n",
    "if RUN_L1:\n",
    "    W1, H1, err1 = NMFL1_IRLS(X, k=K, max_iter=100, inner_iters=3, seed=0)\n",
    "    print(f\"[L1] W:{W1.shape} H:{H1.shape} iters:{len(err1)}  RRE(clean):\",\n",
    "          np.linalg.norm(X_clean - W1 @ H1) / (np.linalg.norm(X_clean) + 1e-12))\n",
    "\n",
    "# ===== 4) （可选）聚类评测 =====\n",
    "if Y.size:\n",
    "    Yp2 = cluster_assign_from_H(H2, Y)\n",
    "    acc2, nmi2 = acc_nmi(Y, Yp2)\n",
    "    print(f\"[L2] ACC={acc2:.4f} NMI={nmi2:.4f}\")\n",
    "    if RUN_L1:\n",
    "        Yp1 = cluster_assign_from_H(H1, Y)\n",
    "        acc1, nmi1 = acc_nmi(Y, Yp1)\n",
    "        print(f\"[L1] ACC={acc1:.4f} NMI={nmi1:.4f}\")\n",
    "\n",
    "# ===== 5) 可视化（字典 & 重构）=====\n",
    "try:\n",
    "    show_dictionary(W2, h, w, cols=8, title=f\"L2 Dictionary (k={K})\")\n",
    "    show_reconstruction(X_clean, W2, H2, h, w, idx=0)\n",
    "except Exception as e:\n",
    "    print(\"visualization skipped:\", e)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
